{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATATHON \n",
    "##### Detecting Pricing Anomalies\n",
    "### IE MBD-O2\n",
    "\n",
    "#### Submission \n",
    "### TEAM C : Amartya | Ceci | Karim | Mike | Pau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](hotelbed.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach Abstract\n",
    "\n",
    "Detecting outliers or anomalies in pricing from the bookings data is an unsupervised learning problem. We will approach the problem with a three-pronged flow:\n",
    "##### 1. Tag Explicit Errors and Meaningless Values\n",
    "##### 2. Remove extreme values contrary to domain standards\n",
    "##### 2. Check for statistical outliers based on calculated Outlier Score\n",
    "##### 3. Cluster similar bookings based on pricipal components and detect statistical outliers\n",
    "\n",
    "\n",
    "<img src=\"Intro.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "We proceed with the above approach while forming 2 basic assumption/hypothesis:\n",
    "1. clusters or features that have higher standard deviations, kurtosis or extreme values are more likely to contain anomalies\n",
    "2. Total anomalies will probably not be higher than 1% of the data set\n",
    "\n",
    "The above approach is implemented by exploring the data set and at each level we create sub-sets of the data that are likely to be anomalies. In the end we combine all of these and create the final tag = 1 for anomalies, 0 for genuine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Initialization](#initialization)\n",
    "2. [Basic Data Exploration,Feature Creation and Transformation](#bda)\n",
    "3. [Feature Analysis](#fa)\n",
    "    1. [ContractID](#contID)\n",
    "    2. [Star Rating](#star)\n",
    "    3. [Room Type](#room)\n",
    "    4. [Arrival Month](#month)\n",
    "    5. [Category](#cat)\n",
    "    6. [Meal Basis](#meal)\n",
    "    7. [Contract Type](#contract)\n",
    "    8. [Other Date Variables](#date)\n",
    "    9. [Time Variables](#time)\n",
    "    10. [City](#city)\n",
    "    11. [Hotel Key](#hotel)\n",
    "4. [Data Set Transformation](#transformation)\n",
    "5. [Outlier/Anomaly Detection](#outlierDetection)    \n",
    "    1. [Statistical and Visual Approach](#stat)\n",
    "    2. [Clustering and Regression Approach](#cluster)\n",
    "5. [Anomaly Labeling and Submission](#submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization <a name=\"initialization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install workdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing primary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "import workdays\n",
    "import glob\n",
    "import datetime\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.feature_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_hkey</th>\n",
       "      <th>contract_id_hkey</th>\n",
       "      <th>id_hkey</th>\n",
       "      <th>city_code</th>\n",
       "      <th>category_room</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>meal_basis</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8311839113995541010</td>\n",
       "      <td>3308171939935307043</td>\n",
       "      <td>-6758561262332566539</td>\n",
       "      <td>1</td>\n",
       "      <td>BL-6</td>\n",
       "      <td>OPQ</td>\n",
       "      <td>APT</td>\n",
       "      <td>RO</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>14192.496000</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7782336419181110673</td>\n",
       "      <td>-3269338087318960614</td>\n",
       "      <td>-9183082468560560492</td>\n",
       "      <td>8</td>\n",
       "      <td>ST</td>\n",
       "      <td>NOR</td>\n",
       "      <td>DBT</td>\n",
       "      <td>BB</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-07-20</td>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>3558.469200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8185637807857201025</td>\n",
       "      <td>-7171383991101553094</td>\n",
       "      <td>-573449065418159891</td>\n",
       "      <td>6</td>\n",
       "      <td>XX-KG-SU</td>\n",
       "      <td>NOR</td>\n",
       "      <td>DBL</td>\n",
       "      <td>RO</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>17319.714354</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4398388086357359587</td>\n",
       "      <td>3421074771505167982</td>\n",
       "      <td>215759992217563846</td>\n",
       "      <td>2</td>\n",
       "      <td>ST</td>\n",
       "      <td>NONE</td>\n",
       "      <td>TWN</td>\n",
       "      <td>BB</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-06-08</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>3321.785004</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7098207282290159573</td>\n",
       "      <td>7965439627984399332</td>\n",
       "      <td>1006074091123194605</td>\n",
       "      <td>7</td>\n",
       "      <td>ST</td>\n",
       "      <td>NOR</td>\n",
       "      <td>DBT</td>\n",
       "      <td>RO</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>2586.300000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hotel_hkey     contract_id_hkey              id_hkey  city_code  \\\n",
       "0 -8311839113995541010  3308171939935307043 -6758561262332566539          1   \n",
       "1 -7782336419181110673 -3269338087318960614 -9183082468560560492          8   \n",
       "2 -8185637807857201025 -7171383991101553094  -573449065418159891          6   \n",
       "3  4398388086357359587  3421074771505167982   215759992217563846          2   \n",
       "4 -7098207282290159573  7965439627984399332  1006074091123194605          7   \n",
       "\n",
       "  category_room contract_type room_type meal_basis creation_date arrival_date  \\\n",
       "0          BL-6           OPQ       APT         RO    2018-05-22   2018-06-30   \n",
       "1            ST           NOR       DBT         BB    2018-05-22   2018-07-20   \n",
       "2      XX-KG-SU           NOR       DBL         RO    2018-05-22   2018-05-24   \n",
       "3            ST          NONE       TWN         BB    2018-05-22   2018-06-08   \n",
       "4            ST           NOR       DBT         RO    2018-05-22   2018-06-11   \n",
       "\n",
       "  departure_date    total_cost star_rating  row_id  \n",
       "0     2018-07-05  14192.496000   APARTMENT       0  \n",
       "1     2018-07-24   3558.469200           1       1  \n",
       "2     2018-05-29  17319.714354           5       2  \n",
       "3     2018-06-11   3321.785004           3       3  \n",
       "4     2018-06-14   2586.300000           3       4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data set\n",
    "df = pd.read_csv('DATATHON_STU_NEW.csv', index_col= 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899477, 14)\n",
      "hotel_hkey            int64\n",
      "contract_id_hkey      int64\n",
      "id_hkey               int64\n",
      "city_code             int64\n",
      "category_room        object\n",
      "contract_type        object\n",
      "room_type            object\n",
      "meal_basis           object\n",
      "creation_date        object\n",
      "arrival_date         object\n",
      "departure_date       object\n",
      "total_cost          float64\n",
      "star_rating          object\n",
      "row_id                int64\n",
      "dtype: object\n",
      "hotel_hkey             0\n",
      "contract_id_hkey       0\n",
      "id_hkey                0\n",
      "city_code              0\n",
      "category_room          0\n",
      "contract_type          0\n",
      "room_type              0\n",
      "meal_basis             0\n",
      "creation_date          0\n",
      "arrival_date           0\n",
      "departure_date         0\n",
      "total_cost          8813\n",
      "star_rating            0\n",
      "row_id                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking properties of the data set\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Exploration,Feature Creation and Transformation <a name=\"bda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with exploring the data set. We first remove the obvious anomalies (step 1 of our approach) which are the Nulls and negetive prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imputing nulls, negatives and zero values for costs into an 'anomaly' Data Frame.\n",
    "df_anomaly1 = df.loc[(df.total_cost <= 0) | (df.total_cost.isnull()),:] \n",
    "df = df.loc[df.total_cost.notnull(), :] \n",
    "df = df.loc[df.total_cost > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8820, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anomaly1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date variable has a lot of features hidden, we extract them and create new feature variables such as month, day etc for arrival, departure and booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition for extracting days from delta time\n",
    "def extractDays(td):\n",
    "    return td.days\n",
    "\n",
    "# Function to calculate working days between 2 dates\n",
    "def cal_weekdays(a):\n",
    "    return(workdays.networkdays(pd.to_datetime(a[0]),pd.to_datetime(a[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic features out of the provided date variable\n",
    "df[\"creation_date_month\"] = pd.DatetimeIndex(pd.to_datetime(df['creation_date'])).month\n",
    "df[\"creation_date_day\"] = pd.DatetimeIndex(pd.to_datetime(df['creation_date'])).day\n",
    "df[\"creation_date_weekday\"] = pd.DatetimeIndex(pd.to_datetime(df['creation_date'])).weekday\n",
    "\n",
    "df[\"arrival_date_month\"] = pd.DatetimeIndex(pd.to_datetime(df['arrival_date'])).month\n",
    "df[\"arrival_date_day\"] = pd.DatetimeIndex(pd.to_datetime(df['arrival_date'])).day\n",
    "df[\"arrival_date_weekday\"] = pd.DatetimeIndex(pd.to_datetime(df['arrival_date'])).weekday\n",
    "\n",
    "df[\"departure_date_month\"] = pd.DatetimeIndex(pd.to_datetime(df['departure_date'])).month\n",
    "df[\"departure_date_day\"] = pd.DatetimeIndex(pd.to_datetime(df['departure_date'])).day\n",
    "df[\"departure_date_weekday\"] = pd.DatetimeIndex(pd.to_datetime(df['departure_date'])).weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the variables previously created we decided to come up with new features based on the departure_date, arrival_date and creation_date:  \n",
    "\n",
    "'**TripNoOfDays**' the duration of the trip\n",
    "\n",
    "'**begEnd**' tuple of arrival_date and departure_date\n",
    "\n",
    "'**TripWorkingDays**' number of working days during the trip\n",
    "\n",
    "'**TripWeekends**' number of weekends during the trip\n",
    "\n",
    "'**BookingLeadTime**' Lead time between booking and start of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TripNoOfDays\"] = pd.DatetimeIndex(pd.to_datetime(df.departure_date)) - pd.DatetimeIndex(pd.to_datetime(df.arrival_date)) \n",
    "\n",
    "df.TripNoOfDays =  df.TripNoOfDays.apply(extractDays)\n",
    "df.TripNoOfDays = df.TripNoOfDays + 1\n",
    "\n",
    "df['begEnd'] = df[['arrival_date', 'departure_date']].apply(tuple, axis=1)\n",
    "df[\"TripWorkingDays\"]  = df.begEnd.apply(cal_weekdays)\n",
    "df[\"TripWeekends\"] =   df.TripNoOfDays -  df.TripWorkingDays\n",
    "df.loc[df.TripWeekends < 0,'TripWeekends'] = 0\n",
    "\n",
    "df[\"BookingLeadTime\"] = pd.DatetimeIndex(pd.to_datetime(df.arrival_date)) - pd.DatetimeIndex(pd.to_datetime(df.creation_date)) \n",
    "df.BookingLeadTime =  df.BookingLeadTime.apply(extractDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature 'price/cost' per night\n",
    "df[\"PricePerNight\"] = df.total_cost / df.TripNoOfDays\n",
    "df[\"PricePerNight\"] = df.PricePerNight.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of 'PriceperNight' in millions\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.distplot(df.loc[:,'PricePerNight']);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New list that comprises all the categorical variables from the Data Frame\n",
    "categoricalVariables = ['city_code','category_room','contract_type','room_type','meal_basis',\n",
    "                       'creation_date_month', 'creation_date_day',\n",
    "                       'creation_date_weekday', 'arrival_date_month', 'arrival_date_day',\n",
    "                       'arrival_date_weekday', 'departure_date_month', 'departure_date_day',\n",
    "                       'departure_date_weekday','star_rating']\n",
    "\n",
    "# Change the variable type of the previous list to 'category'\n",
    "for i in categoricalVariables:\n",
    "    df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variables we no longer need\n",
    "df = df.drop(['id_hkey', 'creation_date', 'arrival_date', 'departure_date', 'begEnd', 'total_cost'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the distribution of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new Data Frames containing all the categorical and numerical features, respectively\n",
    "categoricalVariables = df.select_dtypes(include=['category']).columns\n",
    "numericalVariables = df.select_dtypes(include=['int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel_hkey\n",
      "count    8.906570e+05\n",
      "mean     1.197551e+16\n",
      "std      5.235581e+18\n",
      "min     -9.221152e+18\n",
      "25%     -4.536184e+18\n",
      "50%      2.100855e+17\n",
      "75%      4.423175e+18\n",
      "max      9.220866e+18\n",
      "Name: hotel_hkey, dtype: float64\n",
      "contract_id_hkey\n",
      "count    8.906570e+05\n",
      "mean     4.422421e+17\n",
      "std      5.067546e+18\n",
      "min     -9.223151e+18\n",
      "25%     -3.949640e+18\n",
      "50%      1.474372e+18\n",
      "75%      3.766924e+18\n",
      "max      9.222155e+18\n",
      "Name: contract_id_hkey, dtype: float64\n",
      "city_code\n",
      "count     890657\n",
      "unique         9\n",
      "top            7\n",
      "freq      174059\n",
      "Name: city_code, dtype: int64\n",
      "category_room\n",
      "count     890657\n",
      "unique      1320\n",
      "top           ST\n",
      "freq      407103\n",
      "Name: category_room, dtype: object\n",
      "contract_type\n",
      "count     890657\n",
      "unique         7\n",
      "top          NOR\n",
      "freq      494540\n",
      "Name: contract_type, dtype: object\n",
      "room_type\n",
      "count     890657\n",
      "unique        24\n",
      "top          DBL\n",
      "freq      342523\n",
      "Name: room_type, dtype: object\n",
      "meal_basis\n",
      "count     890657\n",
      "unique        17\n",
      "top           BB\n",
      "freq      416063\n",
      "Name: meal_basis, dtype: object\n",
      "star_rating\n",
      "count     890657\n",
      "unique        22\n",
      "top            4\n",
      "freq      393960\n",
      "Name: star_rating, dtype: object\n",
      "row_id\n",
      "count    890657.000000\n",
      "mean     449688.176876\n",
      "std      259664.668510\n",
      "min           0.000000\n",
      "25%      224820.000000\n",
      "50%      449709.000000\n",
      "75%      674585.000000\n",
      "max      899476.000000\n",
      "Name: row_id, dtype: float64\n",
      "creation_date_month\n",
      "count     890657\n",
      "unique         6\n",
      "top            1\n",
      "freq      160348\n",
      "Name: creation_date_month, dtype: int64\n",
      "creation_date_day\n",
      "count     890657\n",
      "unique        31\n",
      "top           12\n",
      "freq       33627\n",
      "Name: creation_date_day, dtype: int64\n",
      "creation_date_weekday\n",
      "count     890657\n",
      "unique         7\n",
      "top            1\n",
      "freq      154951\n",
      "Name: creation_date_weekday, dtype: int64\n",
      "arrival_date_month\n",
      "count     890657\n",
      "unique        12\n",
      "top            6\n",
      "freq      148073\n",
      "Name: arrival_date_month, dtype: int64\n",
      "arrival_date_day\n",
      "count     890657\n",
      "unique        31\n",
      "top           20\n",
      "freq       31455\n",
      "Name: arrival_date_day, dtype: int64\n",
      "arrival_date_weekday\n",
      "count     890657\n",
      "unique         7\n",
      "top            4\n",
      "freq      140953\n",
      "Name: arrival_date_weekday, dtype: int64\n",
      "departure_date_month\n",
      "count     890657\n",
      "unique        12\n",
      "top            6\n",
      "freq      146318\n",
      "Name: departure_date_month, dtype: int64\n",
      "departure_date_day\n",
      "count     890657\n",
      "unique        31\n",
      "top            1\n",
      "freq       31575\n",
      "Name: departure_date_day, dtype: int64\n",
      "departure_date_weekday\n",
      "count     890657\n",
      "unique         7\n",
      "top            6\n",
      "freq      155106\n",
      "Name: departure_date_weekday, dtype: int64\n",
      "TripNoOfDays\n",
      "count    890657.000000\n",
      "mean          4.424498\n",
      "std           2.712910\n",
      "min           2.000000\n",
      "25%           2.000000\n",
      "50%           4.000000\n",
      "75%           5.000000\n",
      "max         153.000000\n",
      "Name: TripNoOfDays, dtype: float64\n",
      "TripWorkingDays\n",
      "count    890657.000000\n",
      "mean          3.133380\n",
      "std           2.100995\n",
      "min           0.000000\n",
      "25%           2.000000\n",
      "50%           3.000000\n",
      "75%           4.000000\n",
      "max         109.000000\n",
      "Name: TripWorkingDays, dtype: float64\n",
      "TripWeekends\n",
      "count    890657.000000\n",
      "mean          1.291118\n",
      "std           1.068060\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max          44.000000\n",
      "Name: TripWeekends, dtype: float64\n",
      "BookingLeadTime\n",
      "count    890657.000000\n",
      "mean         61.044725\n",
      "std          69.387267\n",
      "min        -727.000000\n",
      "25%          10.000000\n",
      "50%          35.000000\n",
      "75%          89.000000\n",
      "max         756.000000\n",
      "Name: BookingLeadTime, dtype: float64\n",
      "PricePerNight\n",
      "count    8.906570e+05\n",
      "mean     1.198061e+03\n",
      "std      1.287194e+04\n",
      "min      0.000000e+00\n",
      "25%      5.060000e+02\n",
      "50%      8.870000e+02\n",
      "75%      1.494000e+03\n",
      "max      1.184651e+07\n",
      "Name: PricePerNight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Describe all the columns\n",
    "columnNames = df.columns\n",
    "for i in columnNames:\n",
    "    print(i)\n",
    "    print(df[i].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['row_id' 'hotel_hkey' 'contract_id_hkey'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f500c89c17d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop variables that are no longer needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcategoricalVariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategoricalVariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_room'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumericalVariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumericalVariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'row_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hotel_hkey'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'contract_id_hkey'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4387\u001b[0;31m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[1;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"labels ['row_id' 'hotel_hkey' 'contract_id_hkey'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "# Drop variables that are no longer needed\n",
    "categoricalVariables = categoricalVariables.drop(['category_room'])\n",
    "numericalVariables = numericalVariables.drop(['row_id','hotel_hkey','contract_id_hkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the count of occurrences by categories\n",
    "for i,col in enumerate(categoricalVariables):\n",
    "    plt.figure(i,figsize=(15,8))\n",
    "    sns.countplot(df[col],hue = df[col], order=df[col].value_counts().index)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that for many of the categorical variables the distribution/ count is extremely skewed towards a minor group of categories (levels). This provides some evidence to our hypothesis that low count categories with out of normal range prices may be anomalous in nature. Alternatively they can be realistic outliers and not anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the numerical variables \n",
    "for i, col in enumerate(numericalVariables):\n",
    "    plt.figure(i, figsize=(15,8))\n",
    "    sns.distplot(df.loc[:,col])  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In booking lead time, we can observe a left tail corresponding to negative lead times, which are anomalies. However, these anomalies are not price related, this is why we will not include them in the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the price per nigt variable and the cut-off point of the 99.995 percentile\n",
    "print(df.PricePerNight.describe())\n",
    "print(np.percentile(df.PricePerNight, 99.995))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of the points on the left of the 0.005 percentile\n",
    "print(np.percentile(df.PricePerNight, 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We see that the skew is denser upto 99%ile and becomes sparse at higher percentiles. Using basic statistical concepts related to normal distribution, we can assume price values above 99.995% lie as outliers with higher confidence levels. The same statistical rule can be applied on the lower side of the price band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of the points on the left of the 0.01 percentile OR on the right of the 99.995 percentile\n",
    "df.loc[(df.PricePerNight > np.percentile(df.PricePerNight, 99.995)) | (df.PricePerNight < np.percentile(df.PricePerNight, 0.01)) , :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the previous instances into a new Data Frame\n",
    "df_anomaly2 = df.loc[(df.PricePerNight > np.percentile(df.PricePerNight, 99.995)) | (df.PricePerNight < np.percentile(df.PricePerNight, 0.01)) , :]\n",
    "df = df.loc[(df.PricePerNight < np.percentile(df.PricePerNight, 99.995)) & (df.PricePerNight > np.percentile(df.PricePerNight, 0.01)) , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of anomalies inside the dataframe 'df_anomaly2'\n",
    "df_anomaly2.contract_id_hkey.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the cities per hotel against its price\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(df_anomaly2.groupby([\"city_code\", \"contract_id_hkey\"])['PricePerNight'].min().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly they are mostly outliers among this sub data set. For now we can treat them as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the anomalies compressed per night in the Data Frame 'df_anomaly2'\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df_anomaly2.index,df_anomaly2.PricePerNight)\n",
    "plt.ylabel('PricePerNight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis <a name=\"fa\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contract ID Key <a name=\"contID\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The contract ID key represents a aggregation of properties of the booking based on the variables related to the hotel such as hotel, contract type, room type, meal basis and so on. Hence it is a good idea to create mean, median and standard deviation of the records grouped by the contract id. We can use the displacement of the price from these median values (considering the std dev and mean) as indicators of possible outliers or potential anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean 'PricePerNight' grouped by all the contracts id's\n",
    "contractIdMean = df.groupby(['contract_id_hkey'])['PricePerNight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return mean of each contract\n",
    "def getContractMean(cid):\n",
    "    return(contractIdMean[cid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column to store the difference between the 'PricePerNight' and the newly created 'ContractIdMean'\n",
    "df['ContractIdMean'] = df.contract_id_hkey.apply(getContractMean)\n",
    "df['priceDifbyContractMean'] = df['PricePerNight'] - df['ContractIdMean']\n",
    "#df = df.drop(['ContractIdMean'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Star Rating <a name=\"star\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the variable\n",
    "df.star_rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the hotel star rating can be converted to ordinal scale of 1 to 5. For this we compare the median prices of each non numbered category with values of the star ratings for each of the corresponding cities/star. This way we can rank the non numbered star rating categories into numbered star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the 'star_rating' per city against its 'PricePerNight'\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.heatmap(df.groupby([\"city_code\", \"star_rating\"])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\", annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the PricePerNight similarities between cities and star_rating, we grouped them and simplified the amount of categories from 22 to 5: (1,2,3,4,5) as HotelStarRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for Star Rating\n",
    "Hotelratings = {\n",
    "                (\"APARTHOTEL\",0): 5, (\"APARTHOTEL\",1): 4, (\"APARTHOTEL\",3): 3, (\"APARTHOTEL\",4): 4, (\"APARTHOTEL\",5): 4,\n",
    "                (\"APARTHOTEL\",7): 2, (\"APARTHOTEL\",8): 4, (\"APARTMENT\",1): 4, (\"APARTMENT\",4): 4, (\"APARTMENT\",5): 5, \n",
    "                (\"APARTMENT\",7): 4, (\"BED\",0): 1, (\"BED\",1): 4, (\"BED\",2): 4, (\"BED\",4): 3, (\"BED\",8): 1, (\"BOARDING\",1): 4,\n",
    "                (\"BOUTIQUE\",0): 3, (\"BOUTIQUE\",1): 1, (\"BOUTIQUE\",2): 3, (\"BOUTIQUE\",3): 5, (\"BOUTIQUE\",4): 4, \n",
    "                (\"BOUTIQUE\",7): 4, (\"BOUTIQUE\",8): 1, (\"GUEST\",4): 2, (\"GUEST\",5): 1, (\"GUEST\",8): 1, (\"HOSTEL\",1): 1,\n",
    "                (\"HOSTEL\",2): 1, (\"HOSTEL\",3): 1, (\"HOSTEL\",4): 1, (\"HOSTEL\",5): 1, (\"HOSTEL\",6): 1, (\"HOSTEL\",7): 1,\n",
    "                (\"HOSTEL\",8): 1, (\"PENDING\",2): 3, (\"POUSADA\",3): 3, (\"RESIDENCE\",1): 1, (\"RESIDENCE\",4): 5, \n",
    "                (\"RESIDENCE\",5): 4, (\"RESIDENCE\",7): 3, (\"RESORT\",0): 4, (\"RESORT\",3): 5, (\"RESORT\",8): 4, (\"RURAL\",1): 4,\n",
    "                (\"RURAL\",2): 4, (\"RURAL\",8): 4, (\"STANDARD\",0): 4, (\"STANDARD\",7): 3, (\"SUPERIOR\",7): 4, (\"SUPERIOR\",8): 4,\n",
    "                (\"SUPERIOR\",4): 4, (\"SUPERIOR\",0): 4, (\"SUPERIOR\",1): 4, (\"SUPERIOR\",5): 1, (\"VACATIONALS\",1): 4, \n",
    "                (\"VILLA\",0): 5, (\"WITHOUT\",1): 4, (\"WITHOUT\",2): 5, (\"WITHOUT\",3): 4, (\"WITHOUT\",4): 4, (\"WITHOUT\",5): 4,\n",
    "                (\"WITHOUT\",6): 4, (\"WITHOUT\",7): 4\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Return the Star rating of the booked Hotel based on the above Rule\n",
    "def getRating(t):\n",
    "    return(Hotelratings[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variable 'combo' containing a touple with the 'star_rating' and the 'city_code'\n",
    "df['combo'] = df[['star_rating', 'city_code']].apply(tuple, axis=1)\n",
    "\n",
    "# Application of the aforementioned rules into the new feature 'HotelStarRating'\n",
    "df['HotelStarRating'] = 0\n",
    "df.loc[df.star_rating.isin(['5','4','3','2','1']),'HotelStarRating'] = df.star_rating\n",
    "df.loc[df.HotelStarRating == 0, 'HotelStarRating'] =  df.loc[df.HotelStarRating == 0, :].combo.apply(getRating)\n",
    "df.HotelStarRating = df.HotelStarRating.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the variable 'star_rating'so that it returns 'HOTEL' if the instance contains a number of stars\n",
    "df.star_rating = df.star_rating.astype('object')\n",
    "df.loc[df.star_rating.isin(['5','4','3','2','1']),'star_rating'] = 'HOTEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.star_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the edited 'star_rating' variable per city against its price\n",
    "sns.heatmap(df.groupby([\"city_code\", \"star_rating\"])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Return the median and standard deviation of the 'PricePerNight' grouped by the 'star_rating'\n",
    "print(df.groupby([\"star_rating\"])['PricePerNight'].median().sort_values(ascending = False))\n",
    "#print(df.groupby([\"star_rating\"])['PricePerNight'].mean().sort_values(ascending = False))\n",
    "print(df.groupby([\"star_rating\"])['PricePerNight'].std().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the variable 'combo' as we will no longer use it\n",
    "df = df.drop(['combo'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of hotel is not revealing much information. We will thus continue with using the ordinal scale from 1 : 5 as that has greater relevance for understanding the pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Room Type <a name=\"room\"></a>\n",
    "\n",
    "For room type we will take a standard approach of checkinig which room types have higher prices (on an average or as per median). Using this as a metric we will convert the categories into a ranked numerical scale which can have a better correlation to the prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the median of 'PricePerNight' per 'room_type' and count of the records in each type of room\n",
    "print(df.groupby([\"room_type\"])['PricePerNight'].median().sort_values(ascending = False))\n",
    "Counter(df['room_type']).most_common(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a new Data Frame containing the median of the 'PricePerNight' per 'room_type'\n",
    "medianPriceByRoomType = df.groupby([\"room_type\"])['PricePerNight'].median().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this feature into the main Data Frame\n",
    "df['MedianPriceByRoomType'] = 0\n",
    "for i in medianPriceByRoomType.index:\n",
    "    df.loc[df.room_type == i,'MedianPriceByRoomType'] = medianPriceByRoomType[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrival Month <a name=\"month\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our understanding of tourism industry we have an hypothesis that PricePerNight tends to be higher in summer break months and december. We will go ahead and explore the distribution of prices by arrival month and verify this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of the 'PricePerNight' by 'HotelStarRating' and 'arrival_date_month'\n",
    "print(df.groupby([\"arrival_date_month\", \"HotelStarRating\"])['PricePerNight'].median().unstack())\n",
    "\n",
    "# Heatmap of the edited 'arrival_date_month' variable per 'HotelStarRating' against its price\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.groupby([\"HotelStarRating\",\"arrival_date_month\"])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the heatmap we confirm that the previous statement is true, and now a new varible will be created to group months with similar prices and a rank will be assigned based on price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature 'monthRating' that group months with similar prices\n",
    "df['monthRating'] = 0\n",
    "df.loc[df.arrival_date_month.isin(['1','2']), 'monthRating'] = 1\n",
    "df.loc[df.arrival_date_month.isin(['3','4','5']), 'monthRating'] = 5\n",
    "#df.loc[df.arrival_date_month.isin(['11','12']), 'monthRating'] = 4\n",
    "df.loc[df.arrival_date_month.isin(['6','9','10','11']), 'monthRating'] = 25\n",
    "df.loc[df.arrival_date_month.isin(['7','8','12']), 'monthRating'] = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Room <a name=\"cat\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar ranking apporoach will be used for category of the room as well. Since it has > 1000 category levels, not much information can be extracted apart from converting it to an ordinal scale of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number instances in each factor\n",
    "Counter(df['category_room']).most_common(1319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data Frame containing the median 'PricePerNight' be 'category_room'\n",
    "categoryRoomPriceRank = df.groupby([\"category_room\"])['PricePerNight'].median().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating rank for records based on 'room_category'\n",
    "categoryRoomPriceRank = categoryRoomPriceRank.fillna(0)\n",
    "maxi = max(categoryRoomPriceRank)\n",
    "categoryRoomPriceRank = (categoryRoomPriceRank/maxi) * 100\n",
    "categoryRoomPriceRank = categoryRoomPriceRank.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding this feature to the main Data Frame\n",
    "df['categoryRoomPriceRank'] = 0\n",
    "for i in categoryRoomPriceRank.index:\n",
    "    df.loc[df.category_room == i,'categoryRoomPriceRank'] = categoryRoomPriceRank[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.star_rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meal Basis <a name=\"meal\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meal basis will obviously have an influence on the price of the bookings. We can explore which meal categories are higher priced in general. Using this information we can create a score to force a postive correlation between meal basis and price per night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.groupby([\"city_code\",\"meal_basis\"])['PricePerNight'].median().sort_values(ascending= False).unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"meal_basis\", \"HotelStarRating\"])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.groupby([\"city_code\",\"meal_basis\"])['PricePerNight'].std().sort_values(ascending= False).unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([ \"HotelStarRating\",\"meal_basis\"])['PricePerNight'].std().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature for scoring based on the deviation of price from median grouped by 'mealBasis'\n",
    "df['mealBasisDeviation'] = 1\n",
    "df.loc[df.meal_basis.isin(['CB','FB','DB']),'mealBasisDeviation'] = 5\n",
    "df.loc[df.meal_basis.isin(['HB','SC']),'mealBasisDeviation'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"meal_basis\"])['PricePerNight'].median().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"meal_basis\"])['PricePerNight'].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rank variable for 'meal_basis'\n",
    "mealBasisRank = df.groupby([\"meal_basis\"])['PricePerNight'].median().sort_values(ascending = False)\n",
    "mealBasisRank = mealBasisRank.fillna(0)\n",
    "maxi = max(mealBasisRank)\n",
    "mealBasisRank = (mealBasisRank/maxi) * 100\n",
    "mealBasisRank = mealBasisRank.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding this variable to the main Data Frame\n",
    "df['mealBasisRank'] = 0\n",
    "for i in mealBasisRank.index:\n",
    "    df.loc[df.meal_basis == i,'mealBasisRank'] = mealBasisRank[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contract Type <a name=\"contract\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ContractID is already storing information of contract details of each booking. However we will dummify and re-group the contract type variable to reduce the number of levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot describing the distribution of price per type of contract\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.violinplot(x='contract_type', y='PricePerNight', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOR** - Normal\n",
    "\n",
    "**NRF** - Non-Refundable\n",
    "\n",
    "**NONE** - No Contract\n",
    "\n",
    "**OPQ** - Opaque (Selling unsold travel inventory at a discounted price)\n",
    "\n",
    "**NRF/OPQ** - Non-Refundable and Opaque\n",
    "\n",
    "**SPE** - Special\n",
    "\n",
    "**OTH** - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"contract_type\", \"HotelStarRating\"])['PricePerNight'].median().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"contract_type\"])['PricePerNight'].std().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"contract_type\"])['PricePerNight'].count().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"contract_type\"])['PricePerNight'].max().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouping and dummifying the contract type\n",
    "df['contract_NOR'] = 0\n",
    "df.loc[df.contract_type == 'NOR', 'contract_NOR'] = 1\n",
    "\n",
    "df['contract_OPQ'] = 0\n",
    "df.loc[(df.contract_type == 'OPQ')  | (df.contract_type == 'NRF/OPQ') , 'contract_OPQ'] = 1\n",
    "\n",
    "df['contract_NRF'] = 0\n",
    "df.loc[(df.contract_type == 'NRF')  | (df.contract_type == 'NRF/OPQ') , 'contract_NRF'] = 1\n",
    "\n",
    "df['contract_UND'] = 0\n",
    "df.loc[(df.contract_type == 'OTH')  | (df.contract_type == 'NONE') , 'contract_UND'] = 1\n",
    "\n",
    "df['contract_SPE'] = 0\n",
    "df.loc[(df.contract_type == 'SPE'), 'contract_SPE'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature for storing the contract deviation\n",
    "df['contractDeviation'] = 1\n",
    "df.loc[df.contract_type.isin(['OTH','NONE','SPE']),'contractDeviation'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Date Variables <a name=\"date\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateVar = ['creation_date_month', 'creation_date_day', 'creation_date_weekday',\n",
    "           'arrival_date_day', 'arrival_date_weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, var in enumerate(dateVar):\n",
    "    plt.figure(i,figsize=(10,5))\n",
    "    sns.heatmap(df.groupby([\"HotelStarRating\",var])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, var in enumerate(dateVar):\n",
    "    plt.figure(i,figsize=(10,5))\n",
    "    sns.heatmap(df.groupby([\"HotelStarRating\",var])['PricePerNight'].std().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from month (analysed before) date Variables are not adding much value is not adding any additional Value to understand the median prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Variables <a name=\"time\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of price by 'BookingLeadTime'\n",
    "sns.lmplot(x= 'BookingLeadTime', # Horizontal axis\n",
    "           y= 'PricePerNight',   # Vertical axis\n",
    "           data=df,              # Data source\n",
    "           fit_reg=False,        # Don't fix a regression line\n",
    "           );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Trip Days\n",
    "sns.lmplot(x= 'TripNoOfDays',  # Horizontal axis\n",
    "           y= 'PricePerNight', # Vertical axis\n",
    "           data=df,            # Data source\n",
    "           fit_reg=False,      # Don't fix a regression line\n",
    "           );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'TripNoOfDays'])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the higher values of the variables 'TripNoOfDays'\n",
    "df.loc[df.TripNoOfDays.isin(range(15,20)), 'TripNoOfDays'] = 15\n",
    "df.loc[df.TripNoOfDays.isin(range(20,31)), 'TripNoOfDays'] = 25\n",
    "df.loc[df.TripNoOfDays.isin(range(31,45)), 'TripNoOfDays'] = 40\n",
    "df.loc[df.TripNoOfDays.isin(range(45,60)), 'TripNoOfDays'] = 50\n",
    "df.loc[df.TripNoOfDays.isin(range(60,90)), 'TripNoOfDays'] = 80\n",
    "df.loc[df.TripNoOfDays >= 90 , 'TripNoOfDays'] = 100\n",
    "\n",
    "df.groupby(['TripNoOfDays'])['PricePerNight'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'TripNoOfDays'])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'TripNoOfDays'])['PricePerNight'].std().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that time of the trip has an influence on the per night price. Specially the extreme high duration trips. Thus it would be good to bin the higher values of trip duration. Also provide added information on top of the trip duration by creating new variables that store a score based on the trip duration. The standard deviation reveals information on the propensity of a trip to have anomalous pricing. Thus we create new feature to score this propoensity as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature for deviation of price by duration \n",
    "df['DurationDeviation'] = 1\n",
    "df.loc[df.TripNoOfDays.isin(range(7,15)),'DurationDeviation'] = 5\n",
    "df.loc[df.TripNoOfDays.isin(range(15,50)),'DurationDeviation'] = 25\n",
    "df.loc[df.TripNoOfDays > 50 ,'DurationDeviation'] = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking trip duration\n",
    "df['durationType'] = 1\n",
    "df.loc[df.TripNoOfDays.isin(range(7,12)), 'durationType'] = 20\n",
    "df.loc[df.TripNoOfDays.isin(range(12,50)), 'durationType'] = 5\n",
    "df.loc[df.TripNoOfDays > 50, 'durationType'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['TripWeekends'])['PricePerNight'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'TripWeekends'])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'TripWeekends'])['PricePerNight'].std().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar approach can be taken for the trip duration as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating trip weekends just like trip duration\n",
    "df.loc[df.TripWeekends.isin(range(5,11)), 'TripWeekends'] = 5\n",
    "df.loc[df.TripWeekends >= 11 , 'TripWeekends'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WeekendIncluded'] = 0\n",
    "df.loc[(df.TripWeekends > 0), 'WeekendIncluded' ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby([\"HotelStarRating\",'WeekendIncluded'])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City <a name=\"city\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby(['HotelStarRating',\"city_code\"])['PricePerNight'].count().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby(['HotelStarRating',\"city_code\"])['PricePerNight'].median().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby(['HotelStarRating',\"city_code\"])['PricePerNight'].min().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.groupby(['HotelStarRating',\"city_code\"])['PricePerNight'].std().unstack()\n",
    "            ,linewidths=.5, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heat map we can clearly identfy cities that have relatively higher prices. We can hence group the cities and rank them based on the 'cost of living' that can be deduced from the exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the cities based on median prices\n",
    "df['cityRank'] = 1\n",
    "df.loc[df.city_code.isin([5,6]), 'cityRank'] = 9\n",
    "df.loc[df.city_code.isin([1,4,7,8]), 'cityRank'] = 3\n",
    "\n",
    "df['cityDeviation'] = 1\n",
    "df.loc[df.city_code.isin([8,5,1]), 'cityDeviation'] = 9\n",
    "df.loc[df.city_code.isin([7,6,1]), 'cityDeviation'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution of the price per city\n",
    "for i, city in enumerate(df.city_code.cat.categories):\n",
    "    plt.figure(i)\n",
    "    #sns.distplot(train_data.loc[:,col], bins= 2)\n",
    "    sns.distplot(df.loc[(df.city_code == city),'PricePerNight'])\n",
    "    plt.xlabel(city, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable that takes into account the kurtosis for the previously plotted distributions\n",
    "df['CityKurtosis'] = 0\n",
    "for i, city in enumerate(df.city_code.cat.categories):\n",
    "    df.loc[(df.city_code == city),'CityKurtosis'] = df.loc[(df.city_code == city),'PricePerNight'].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.CityKurtosis = df.CityKurtosis.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hotel Key <a name=\"hotel\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though it makes sense to treat it just like contract, the information is already captured in the contractID and other hotel features. Thus it will not add any additional values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation and Transformation of Data Set <a name=\"transformation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MedianPriceByRoomType = df.MedianPriceByRoomType.astype('int')\n",
    "df.ContractIdMean = df.ContractIdMean.astype('int')\n",
    "df.priceDifbyContractMean = df.priceDifbyContractMean.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables that are no longer needed\n",
    "df = df.drop(['hotel_hkey', 'contract_id_hkey', 'city_code', 'category_room',\n",
    "       'contract_type', 'room_type', 'meal_basis', 'star_rating',\n",
    "       'creation_date_month', 'creation_date_day', 'creation_date_weekday',\n",
    "       'arrival_date_month', 'arrival_date_day', 'arrival_date_weekday',\n",
    "       'departure_date_month', 'departure_date_day', 'departure_date_weekday',\n",
    "       ],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have transformed the entire categorical data set into a purely numerical one. This way we can go ahead and apply statistical rules and models based on continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the transformed dataset before diving into outlier detection\n",
    "df.to_csv('TransformedData.csv', sep=',', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTLIER/ANOMALY DETECTION <a name=\"outlierDetection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier we will proceed with a 2 fold process here. First we will create outlier score based on the features that explain the deviation of the price from the expected mean or median. This will be used to detect price points which have a high probability of being anomalouos. The actual price recorded will also be taken into consideration while making this criteria.\n",
    "The second approach will use clustering and regression to group similar bookings together and define outliers based on regression scores and residuals for each of fthe clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling dataset\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = standard_scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(np_scaled, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical and Visualization Approach <a name=\"stat\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the deviation columns and create an outlier score\n",
    "df_scaled['outlierScore'] = ((df_scaled.priceDifbyContractMean*100) *\n",
    "                            ((df_scaled.mealBasisDeviation + df_scaled.contractDeviation + \n",
    "                            df_scaled.DurationDeviation + df_scaled.cityDeviation + df_scaled.CityKurtosis) * 10 ))\n",
    "df_scaled['outlierScore'] = preprocessing.scale(df_scaled['outlierScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot of the outlier score over price\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df_scaled.outlierScore,df_scaled.PricePerNight)\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Outlier Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion of the data points shows clearly that extremely high outlier scores on either side can be treated as anomalies. Thus high outlier score and high prices on the extreme ends of the distribution (including the negetive side of outlier score) can be tagged as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returning the outliers from both sides of the distribution\n",
    "\n",
    "# On the positive side\n",
    "print(df_scaled.loc[(df_scaled.outlierScore > 30), 'PricePerNight'].size) # 10\n",
    "print(df_scaled.loc[((df_scaled.outlierScore > 20) & (df_scaled.outlierScore < 30)) & (df_scaled.PricePerNight > 12), 'PricePerNight'].size) # 10\n",
    "\n",
    "# On the negative side\n",
    "print(df_scaled.loc[(df_scaled.outlierScore < -15) & (df_scaled.PricePerNight < 5), 'PricePerNight'].size)\n",
    "print(df_scaled.loc[(df_scaled.outlierScore < -15) & (df_scaled.PricePerNight > 15), 'PricePerNight'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boundary conditions are set based on the distribution observed in the scatter plot above and also keeping tight rules to allow for lower probability of False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data Frame containing the previously spotted anomalies\n",
    "df_anomaly3 = pd.DataFrame( df_scaled.loc[ \n",
    "                   (df_scaled.outlierScore > 30)\n",
    "                 | (((df_scaled.outlierScore > 20) & (df_scaled.outlierScore < 30)) & (df_scaled.PricePerNight > 12))\n",
    "                 | ((df_scaled.outlierScore < -15) & (df_scaled.PricePerNight < 5))\n",
    "                 | ((df_scaled.outlierScore < -15) & (df_scaled.PricePerNight > 15))\n",
    "                  , 'PricePerNight'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.loc[df_scaled.index.isin(df_anomaly3.index) == False , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the variables that we will not use anymore\n",
    "df_scaled = df_scaled.drop(['priceDifbyContractMean' , 'mealBasisDeviation', \n",
    "                            'contractDeviation', 'DurationDeviation', 'cityDeviation', \n",
    "                            'CityKurtosis', 'outlierScore'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster and Regression Approach <a name=\"cluster\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PricePerNight = data.PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PricePerNight'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take useful features and standardize them\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = standard_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columNames = df_scaled.columns.drop(['PricePerNight'])\n",
    "data.columns = columNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We begin with PCA to capture the variations as much as possible without having to perform arbitrary feature selection. We have a total of 18 featuers (hence 18 PC) of which we will retain enough to capture atleas 80% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "# reduce to 10 importants features\n",
    "pca = PCA(n_components=10)\n",
    "data_PCA = pca.fit_transform(data)\n",
    "data_PCA = pd.DataFrame(data_PCA, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize these 10 new features\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = standard_scaler.fit_transform(data_PCA)\n",
    "data_PCA = pd.DataFrame(np_scaled, index=data_PCA.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide on the clustering we will go by the standard elbow curve approach. However, we need to ensure that we chose < 10 clusters (since PC = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate with different number of centroids to see the loss-plot (elbow method)\n",
    "n_cluster = range(3, 11)\n",
    "kmeans = [KMeans(n_clusters=i).fit(data_PCA) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data_PCA) for i in range(len(kmeans))]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 clusters (start at 3)\n",
    "km = kmeans[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA['BookingCluster'] = km.predict(data_PCA)\n",
    "#df['principal_feature1'] = data[0]\n",
    "#df['principal_feature2'] = data[1]\n",
    "#df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA.groupby(['BookingCluster']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCA['PricePerNight'] = PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, cls in enumerate(data_PCA.BookingCluster.unique()):\n",
    "    plt.figure(i,figsize=(15,8))\n",
    "    sns.distplot(data_PCA.loc[(data_PCA.BookingCluster == cls),'PricePerNight'])\n",
    "    plt.xlabel(cls, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see similar distributions of prices in each. A fair assumption would be that clusters are dense around the centroids representing similar bookings. Outlier prices would be on the tails of the distribution. By running a regression line on the clusters for the prices, we can identify the outliers in each clusters. These would represent price points which do not make much sense as per the cluster centroids. \n",
    "##### (The logic is similar to that of Local Outlier Model, except that we are building statistical rules for an external variable - PricePerNight here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Modeling for each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = [None] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Data Frames for each of the 8 clusters\n",
    "for i in range(0,8):\n",
    "    df_cluster[i] = data_PCA.loc[data_PCA.BookingCluster == i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build regression models on each of the clusters. The outlier selection criteria will be based on \n",
    "1. Regression scores - R2 and RMSE, Kurtosis (high and low defines clusters better ie. easier to interpret outliers)\n",
    "2. Price points and assumption 2(<1% anomalies) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[0].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[0].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 4.5\n",
    "leftThreshold = -2.3\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_0_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_0_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_0_anomalies.shape)\n",
    "cluster_0_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[1].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[1].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 13\n",
    "leftThreshold = -3\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_1_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_1_anomalies.shape)\n",
    "cluster_1_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[2].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[2].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 6\n",
    "leftThreshold = -2.5\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_2_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_2_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_2_anomalies.shape)\n",
    "cluster_2_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[3].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[3].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rightThreshold = 5.5\n",
    "leftThreshold = -3\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_3_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_3_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_3_anomalies.shape)\n",
    "cluster_3_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[4].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[4].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 7\n",
    "leftThreshold = -3\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_4_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_4_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_4_anomalies.shape)\n",
    "cluster_4_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[5].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[5].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 7\n",
    "leftThreshold = -3.1\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_5_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_5_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_5_anomalies.shape)\n",
    "cluster_5_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[6].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[6].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 10\n",
    "leftThreshold = -4\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_6_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_6_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_6_anomalies.shape)\n",
    "cluster_6_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[7].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_cluster[7].drop(['PricePerNight','BookingCluster'], axis = 1)\n",
    "labels = df_cluster[7].PricePerNight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regMod = linear_model.LinearRegression()\n",
    "regMod.fit(train, labels)\n",
    "pricePred = regMod.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(labels,pricePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(labels,pricePred) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = labels - pricePred\n",
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(residuals.index,residuals)\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(residuals)\n",
    "plt.xlabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightThreshold = 8\n",
    "leftThreshold = -3\n",
    "print(residuals[residuals>rightThreshold].size)\n",
    "print(residuals[residuals<leftThreshold].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_7_anomalies = pd.DataFrame(residuals[(residuals>rightThreshold) | (residuals < leftThreshold)])\n",
    "cluster_7_anomalies.columns=['Residuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_7_anomalies.shape)\n",
    "cluster_7_anomalies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalyPred = cluster_0_anomalies.append([\n",
    "                                             cluster_1_anomalies,\n",
    "                                             cluster_2_anomalies,\n",
    "                                             cluster_3_anomalies,\n",
    "                                             cluster_4_anomalies,\n",
    "                                             cluster_5_anomalies,\n",
    "                                             cluster_6_anomalies,\n",
    "                                             cluster_7_anomalies,\n",
    "                                             ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalyPred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalyPred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Summary1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Labeling and Submission <a name=\"submit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a description of the anomalies\n",
    "print(df_anomaly1.index)\n",
    "print(df_anomaly1.index.shape)\n",
    "print(df_anomaly1.index.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_anomaly2.index)\n",
    "print(df_anomaly2.index.shape)\n",
    "print(df_anomaly2.index.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_anomaly3.index)\n",
    "print(df_anomaly3.index.shape)\n",
    "print(df_anomaly3.index.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_anomalyPred.index)\n",
    "print(df_anomalyPred.index.shape)\n",
    "print(df_anomalyPred.index.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly3.index.isin(df_anomalyPred.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation of all the anomalies indexes\n",
    "anomalyIndex = df_anomaly1.index.append([df_anomaly2.index,df_anomaly3.index,df_anomalyPred.index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyIndex.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyIndex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variable 'anomaly' for final submission\n",
    "finalPrediction =  pd.read_csv('DATATHON_STU_NEW.csv', index_col= 0)\n",
    "finalPrediction = pd.DataFrame(finalPrediction.loc[:,'row_id'])\n",
    "finalPrediction['anomaly'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPrediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPrediction.loc[finalPrediction.row_id.isin(anomalyIndex),'anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL ANOMALIES IDENTIFIED:\")\n",
    "print(finalPrediction.anomaly.sum())\n",
    "\n",
    "print(\"TOTAL ANOMALIES Percentage:\")\n",
    "print(round(((finalPrediction.anomaly.sum()/finalPrediction.shape[0])*100),2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final submission dataset\n",
    "finalPrediction.to_csv('TeamC_FinalPrediction.csv', sep=',', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------END OF DOCUMENT--------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
